{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a25a8e",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912703a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7251203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6fc380",
   "metadata": {},
   "source": [
    "### Setup device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73dd971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de49339",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d5dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7607c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "CUDA Version: 12.1\n",
      "PyTorch Version: 2.5.1+cu121\n",
      "Torchvision Version: 0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# CUDA Diagnostics\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecbc8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e33487",
   "metadata": {},
   "source": [
    "### Setting the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ed25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0003\n",
    "PATCH_SIZE = 4\n",
    "NUM_CLASSES = 10\n",
    "IMAGE_SIZE = 32\n",
    "EMBED_DIM = 256\n",
    "DEPTH = 6\n",
    "MLP_DIM = 512\n",
    "DROP_RATE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b4779",
   "metadata": {},
   "source": [
    "### Define image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5b5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)), #helps the model to converge faster, also helps to make the numerical computation stable\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fb4b0",
   "metadata": {},
   "source": [
    "### Getting a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd5f7b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='data',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc0d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.CIFAR10(root='data',\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7140a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=0.5, std=0.5)\n",
       "           )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a96c1841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=0.5, std=0.5)\n",
       "           )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb47baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7de6c",
   "metadata": {},
   "source": [
    "### Converting the datasets into dataloaders:\n",
    "Our data is in the form of pytorch dataset, data,oasers turn the data into batches or mini-batches that makes more computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f916f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1657bcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader: (<torch.utils.data.dataloader.DataLoader object at 0x0000022249D6C110>, <torch.utils.data.dataloader.DataLoader object at 0x0000022270C883D0>)\n",
      "Length of train_loader: 391\n",
      "Length of test_loader: 79\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataLoader: {train_loader, test_loader}\")\n",
    "print(f\"Length of train_loader: {len(train_loader)}\")\n",
    "print(f\"Length of test_loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bced7a8",
   "metadata": {},
   "source": [
    "### Building vision transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f58c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3884967341.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aienv)",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
